{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import editdistance\n",
    "from path import Path\n",
    "\n",
    "from DataLoaderIAM import DataLoaderIAM, Batch\n",
    "from Model import Model, DecoderType\n",
    "from SamplePreprocessor import preprocess\n",
    "\n",
    "#path = input(\"Enter path of an image: \")\n",
    "#path = \"../data/new/\" + path\n",
    "\n",
    "class FilePaths:\n",
    "    \"filenames and paths to data\"\n",
    "    fnCharList = '../model/charList.txt'\n",
    "    fnSummary = '../model/summary.json'\n",
    "    #fnInfer = path\n",
    "    fnCorpus = '../data/corpus.txt'\n",
    "\n",
    "\n",
    "def write_summary(charErrorRates, wordAccuracies):\n",
    "    with open(FilePaths.fnSummary, 'w') as f:\n",
    "        json.dump({'charErrorRates': charErrorRates, 'wordAccuracies': wordAccuracies}, f)\n",
    "\n",
    "\n",
    "def train(model, loader):\n",
    "    \"train NN\"\n",
    "    epoch = 0  # number of training epochs since start\n",
    "    summaryCharErrorRates = []\n",
    "    summaryWordAccuracies = []\n",
    "    bestCharErrorRate = float('inf')  # best valdiation character error rate\n",
    "    noImprovementSince = 0  # number of epochs no improvement of character error rate occured\n",
    "    earlyStopping = 25  # stop training after this number of epochs without improvement\n",
    "    while True:\n",
    "        epoch += 1\n",
    "        print('Epoch:', epoch)\n",
    "\n",
    "        # train\n",
    "        print('Train NN')\n",
    "        loader.trainSet()\n",
    "        while loader.hasNext():\n",
    "            iterInfo = loader.getIteratorInfo()\n",
    "            batch = loader.getNext()\n",
    "            loss = model.trainBatch(batch)\n",
    "            print(f'Epoch: {epoch} Batch: {iterInfo[0]}/{iterInfo[1]} Loss: {loss}')\n",
    "\n",
    "        # validate\n",
    "        charErrorRate, wordAccuracy = validate(model, loader)\n",
    "\n",
    "        # write summary\n",
    "        summaryCharErrorRates.append(charErrorRate)\n",
    "        summaryWordAccuracies.append(wordAccuracy)\n",
    "        write_summary(summaryCharErrorRates, summaryWordAccuracies)\n",
    "\n",
    "        # if best validation accuracy so far, save model parameters\n",
    "        if charErrorRate < bestCharErrorRate:\n",
    "            print('Character error rate improved, save model')\n",
    "            bestCharErrorRate = charErrorRate\n",
    "            noImprovementSince = 0\n",
    "            model.save()\n",
    "        else:\n",
    "            print(f'Character error rate not improved, best so far: {charErrorRate * 100.0}%')\n",
    "            noImprovementSince += 1\n",
    "\n",
    "        # stop training if no more improvement in the last x epochs\n",
    "        if noImprovementSince >= earlyStopping:\n",
    "            print(f'No more improvement since {earlyStopping} epochs. Training stopped.')\n",
    "            break\n",
    "\n",
    "\n",
    "def validate(model, loader):\n",
    "    \"validate NN\"\n",
    "    print('Validate NN')\n",
    "    loader.validationSet()\n",
    "    numCharErr = 0\n",
    "    numCharTotal = 0\n",
    "    numWordOK = 0\n",
    "    numWordTotal = 0\n",
    "    while loader.hasNext():\n",
    "        iterInfo = loader.getIteratorInfo()\n",
    "        print(f'Batch: {iterInfo[0]} / {iterInfo[1]}')\n",
    "        batch = loader.getNext()\n",
    "        (recognized, _) = model.inferBatch(batch)\n",
    "\n",
    "        print('Ground truth -> Recognized')\n",
    "        for i in range(len(recognized)):\n",
    "            numWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n",
    "            numWordTotal += 1\n",
    "            dist = editdistance.eval(recognized[i], batch.gtTexts[i])\n",
    "            numCharErr += dist\n",
    "            numCharTotal += len(batch.gtTexts[i])\n",
    "            print('[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' + batch.gtTexts[i] + '\"', '->',\n",
    "                  '\"' + recognized[i] + '\"')\n",
    "\n",
    "    # print validation result\n",
    "    charErrorRate = numCharErr / numCharTotal\n",
    "    wordAccuracy = numWordOK / numWordTotal\n",
    "    print(f'Character error rate: {charErrorRate * 100.0}%. Word accuracy: {wordAccuracy * 100.0}%.')\n",
    "    return charErrorRate, wordAccuracy\n",
    "\n",
    "\n",
    "def infer(model, fnImg):\n",
    "    \"recognize text in image provided by file path\"\n",
    "    img = preprocess(cv2.imread(fnImg, cv2.IMREAD_GRAYSCALE), Model.imgSize)\n",
    "    batch = Batch(None, [img])\n",
    "    (recognized, probability) = model.inferBatch(batch, True)\n",
    "    #print(f'Predicted Text : \" {recognized[0]} \"')\n",
    "    return recognized[0]\n",
    "    #print(f'Probability: {probability[0]}')\n",
    "\n",
    "\n",
    "def main(fnInfer):\n",
    "    \"main function\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train', help='train the NN', action='store_true')\n",
    "    parser.add_argument('--validate', help='validate the NN', action='store_true')\n",
    "    parser.add_argument('--decoder', choices=['bestpath', 'beamsearch', 'wordbeamsearch'], default='bestpath',\n",
    "                        help='CTC decoder')\n",
    "    parser.add_argument('--batch_size', help='batch size', type=int, default=100)\n",
    "    parser.add_argument('--data_dir', help='directory containing IAM dataset', type=Path, required=False)\n",
    "    parser.add_argument('--fast', help='use lmdb to load images', action='store_true')\n",
    "    parser.add_argument('--dump', help='dump output of NN to CSV file(s)', action='store_true')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # set chosen CTC decoder\n",
    "    if args.decoder == 'bestpath':\n",
    "        decoderType = DecoderType.BestPath\n",
    "    elif args.decoder == 'beamsearch':\n",
    "        decoderType = DecoderType.BeamSearch\n",
    "    elif args.decoder == 'wordbeamsearch':\n",
    "        decoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "    # train or validate on IAM dataset\n",
    "    if args.train or args.validate:\n",
    "        # load training data, create TF model\n",
    "        loader = DataLoaderIAM(args.data_dir, args.batch_size, Model.imgSize, Model.maxTextLen, args.fast)\n",
    "\n",
    "        # save characters of model for inference mode\n",
    "        open(FilePaths.fnCharList, 'w').write(str().join(loader.charList))\n",
    "\n",
    "        # save words contained in dataset into file\n",
    "        open(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
    "\n",
    "        # execute training or validation\n",
    "        if args.train:\n",
    "            model = Model(loader.charList, decoderType)\n",
    "            train(model, loader)\n",
    "        elif args.validate:\n",
    "            model = Model(loader.charList, decoderType, mustRestore=True)\n",
    "            validate(model, loader)\n",
    "\n",
    "    # infer text on test image\n",
    "    else:\n",
    "        model = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=True, dump=args.dump)\n",
    "        x = infer(model, fnInfer)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "[2021-04-19 23:31:16,080] ERROR in app: Exception on / [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-4-4a8c3a87a183>\", line 21, in home_page\n",
      "    return render_template('index.html')\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\templating.py\", line 138, in render_template\n",
      "    ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\jinja2\\environment.py\", line 930, in get_or_select_template\n",
      "    return self.get_template(template_name_or_list, parent, globals)\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\jinja2\\environment.py\", line 883, in get_template\n",
      "    return self._load_template(name, self.make_globals(globals))\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\jinja2\\environment.py\", line 857, in _load_template\n",
      "    template = self.loader.load(self, name, globals)\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\jinja2\\loaders.py\", line 115, in load\n",
      "    source, filename, uptodate = self.get_source(environment, name)\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\templating.py\", line 60, in get_source\n",
      "    return self._get_source_fast(environment, template)\n",
      "  File \"G:\\Anaconda\\lib\\site-packages\\flask\\templating.py\", line 89, in _get_source_fast\n",
      "    raise TemplateNotFound(template)\n",
      "jinja2.exceptions.TemplateNotFound: index.html\n",
      "127.0.0.1 - - [19/Apr/2021 23:31:16] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [19/Apr/2021 23:31:17] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "\n",
    "# define a folder to store and later serve the images\n",
    "UPLOAD_FOLDER = 'static/uploads/'\n",
    "\n",
    "# allow files of a specific type\n",
    "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg','jfif'])\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# function to check the file extension\n",
    "def allowed_file(filename):  \n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "# route and function to handle the home page\n",
    "@app.route('/')\n",
    "def home_page():  \n",
    "    return render_template('index.html')\n",
    "\n",
    "# route and function to handle the upload page\n",
    "@app.route('/upload', methods=['GET', 'POST'])\n",
    "def upload_page():\n",
    "    global disease\n",
    "    disease = ''\n",
    "    if request.method == 'POST':\n",
    "        # check if there is a file in the request\n",
    "        if 'file' not in request.files:\n",
    "            return render_template('upload.html', msg='No file selected')\n",
    "        file = request.files['file']\n",
    "        # if no file is selected\n",
    "        if file.filename == '':\n",
    "            return render_template('upload.html', msg='No file selected')\n",
    "        \n",
    "        file.save(os.path.join(UPLOAD_FOLDER, file.filename))\n",
    "\n",
    "        if file and allowed_file(file.filename):\n",
    "\n",
    "            \n",
    "            img_src=UPLOAD_FOLDER + file.filename\n",
    "            disease = main(img_src)\n",
    "\n",
    "           \n",
    "            return render_template('upload.html',\n",
    "                                   msg='Successfully processed:\\n'+file.filename,\n",
    "                                   disease=disease,\n",
    "                                   img_src=UPLOAD_FOLDER + file.filename)\n",
    "    elif request.method == 'GET':\n",
    "        return render_template('upload.html')\n",
    "if __name__ == '__main__':  \n",
    "    app.run(debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
